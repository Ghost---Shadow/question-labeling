wandb:
  project: "question_labeling"
  name: "gpt35_mpnet_avg"
  # entity: "carml"

architecture:
  question_generator_model:
    name: 'gpt-3.5-turbo'
  
  semantic_search_model:
    name: 'sentence_transformer'
    checkpoint: 'all-mpnet-base-v2'
    device: "cuda:0"

  aggregation_strategy:
    name: 'average'

  loss:
    name: 'mse'

dataset:
  name: 'hotpot_qa_with_q'

training:
  strategy:
    name: 'iterative_strategy'
  epochs: 10
  batch_size: 2
  learning_rate: 1e-6
  seeds: [42]
  # seeds: [42, 43, 44, 45, 46]

eval:
  k: [5, 10, 15]
